{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e40f51",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-06T02:37:13.094926Z",
     "iopub.status.busy": "2023-09-06T02:37:13.094548Z",
     "iopub.status.idle": "2023-09-06T02:37:40.179622Z",
     "shell.execute_reply": "2023-09-06T02:37:40.178477Z"
    },
    "papermill": {
     "duration": 27.098085,
     "end_time": "2023-09-06T02:37:40.182105",
     "exception": false,
     "start_time": "2023-09-06T02:37:13.084020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/autocorrect/autocorrect-2.6.1.tar\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: autocorrect\r\n",
      "  Building wheel for autocorrect (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622363 sha256=80799778c87dbf3a9ca9b98b945677c8611b78262cd1b86a11487819bca893a2\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/db/69/42/0fb0421d2fe70d195a04665edc760cfe5fd341d7bb8d8e0aaa\r\n",
      "Successfully built autocorrect\r\n",
      "Installing collected packages: autocorrect\r\n",
      "Successfully installed autocorrect-2.6.1\r\n",
      "Processing /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n",
    "!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e0fd5d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T02:37:40.198897Z",
     "iopub.status.busy": "2023-09-06T02:37:40.198587Z",
     "iopub.status.idle": "2023-09-06T02:37:59.815623Z",
     "shell.execute_reply": "2023-09-06T02:37:59.814686Z"
    },
    "papermill": {
     "duration": 19.628721,
     "end_time": "2023-09-06T02:37:59.818558",
     "exception": false,
     "start_time": "2023-09-06T02:37:40.189837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset,load_dataset, load_from_disk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric, disable_progress_bar\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import re\n",
    "from autocorrect import Speller\n",
    "from spellchecker import SpellChecker\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "disable_progress_bar()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda0e757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T02:37:59.834629Z",
     "iopub.status.busy": "2023-09-06T02:37:59.834374Z",
     "iopub.status.idle": "2023-09-06T02:37:59.844834Z",
     "shell.execute_reply": "2023-09-06T02:37:59.844016Z"
    },
    "papermill": {
     "duration": 0.020818,
     "end_time": "2023-09-06T02:37:59.846892",
     "exception": false,
     "start_time": "2023-09-06T02:37:59.826074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random seed function\n",
    "# 随机种子函数\n",
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f816b2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T02:37:59.862303Z",
     "iopub.status.busy": "2023-09-06T02:37:59.862104Z",
     "iopub.status.idle": "2023-09-06T02:37:59.867259Z",
     "shell.execute_reply": "2023-09-06T02:37:59.866451Z"
    },
    "papermill": {
     "duration": 0.015253,
     "end_time": "2023-09-06T02:37:59.869255",
     "exception": false,
     "start_time": "2023-09-06T02:37:59.854002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set configuration\n",
    "# 设置配置类\n",
    "class CFG:\n",
    "    model_name=\"debertav3base\"\n",
    "    learning_rate=1.5e-5\n",
    "    weight_decay=0.02\n",
    "    hidden_dropout_prob=0.007\n",
    "    attention_probs_dropout_prob=0.007\n",
    "    num_train_epochs=5\n",
    "    n_splits=4\n",
    "    batch_size=12\n",
    "    random_seed=42\n",
    "    save_steps=100\n",
    "    max_length=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "544f969b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T02:37:59.884891Z",
     "iopub.status.busy": "2023-09-06T02:37:59.884433Z",
     "iopub.status.idle": "2023-09-06T02:37:59.907456Z",
     "shell.execute_reply": "2023-09-06T02:37:59.906655Z"
    },
    "papermill": {
     "duration": 0.033352,
     "end_time": "2023-09-06T02:37:59.909751",
     "exception": false,
     "start_time": "2023-09-06T02:37:59.876399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n",
    "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
    "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
    "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c87352e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T02:37:59.925805Z",
     "iopub.status.busy": "2023-09-06T02:37:59.925609Z",
     "iopub.status.idle": "2023-09-06T02:38:02.381522Z",
     "shell.execute_reply": "2023-09-06T02:38:02.380550Z"
    },
    "papermill": {
     "duration": 2.46708,
     "end_time": "2023-09-06T02:38:02.384261",
     "exception": false,
     "start_time": "2023-09-06T02:37:59.917181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 下面是比较重要的部分：数据预处理。\n",
    "class Preprocessor:\n",
    "    def __init__(self, \n",
    "                model_name: str,\n",
    "                ) -> None: #初始化方法，接受一个字符串参数 model_name，用于构建预处理器实例。在初始化过程中，它创建了许多预处理所需的工具，如 tokenizer、词汇表、停用词集合等。 \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        self.twd = TreebankWordDetokenizer()\n",
    "        self.STOP_WORDS = set(stopwords.words('english'))\n",
    "        \n",
    "        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n",
    "        self.speller = Speller(lang='en')\n",
    "        self.spellchecker = SpellChecker() \n",
    "        \n",
    "    def word_overlap_count(self, row): # 计算两个文本序列中词语的交集数量。使用 prompt_tokens 和 summary_tokens 字段中的词语。\n",
    "        \"\"\" intersection(prompt_text, text) \"\"\"        \n",
    "        def check_is_stop_word(word):\n",
    "            return word in self.STOP_WORDS\n",
    "        \n",
    "        prompt_words = row['prompt_tokens']\n",
    "        summary_words = row['summary_tokens']\n",
    "        if self.STOP_WORDS:\n",
    "            prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
    "            summary_words = list(filter(check_is_stop_word, summary_words))\n",
    "        return len(set(prompt_words).intersection(set(summary_words)))\n",
    "            \n",
    "    def ngrams(self, token, n): # 生成文本序列的 n-gram。将输入的 token 列表分割为 n-gram，并返回 n-gram 列表.\n",
    "        # Use the zip function to help us generate n-grams\n",
    "        # Concatentate the tokens into ngrams and return\n",
    "        ngrams = zip(*[token[i:] for i in range(n)])\n",
    "        return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "    def ngram_co_occurrence(self, row, n: int) -> int: # 计算原始文本和摘要文本的 n-gram 共现数量。\n",
    "        # Tokenize the original text and summary into words\n",
    "        original_tokens = row['prompt_tokens']\n",
    "        summary_tokens = row['summary_tokens']\n",
    "\n",
    "        # Generate n-grams for the original text and summary\n",
    "        original_ngrams = set(self.ngrams(original_tokens, n))\n",
    "        summary_ngrams = set(self.ngrams(summary_tokens, n))\n",
    "\n",
    "        # Calculate the number of common n-grams\n",
    "        common_ngrams = original_ngrams.intersection(summary_ngrams)\n",
    "        return len(common_ngrams)\n",
    "    \n",
    "    def ner_overlap_count(self, row, mode:str): #计算两个文本中命名实体（Named Entity）的交集数量。使用 spacy 或 stanza 模型提取命名实体。\n",
    "        model = self.spacy_ner_model\n",
    "        def clean_ners(ner_list):\n",
    "            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n",
    "        prompt = model(row['prompt_text'])\n",
    "        summary = model(row['text'])\n",
    "\n",
    "        if \"spacy\" in str(model):\n",
    "            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n",
    "            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n",
    "        elif \"stanza\" in str(model):\n",
    "            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n",
    "            summary_ner = set([(token.text, token.type) for token in summary.ents])\n",
    "        else:\n",
    "            raise Exception(\"Model not supported\")\n",
    "\n",
    "        prompt_ner = clean_ners(prompt_ner)\n",
    "        summary_ner = clean_ners(summary_ner)\n",
    "\n",
    "        intersecting_ners = prompt_ner.intersection(summary_ner)\n",
    "        \n",
    "        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            return ner_dict\n",
    "        elif mode == \"test\":\n",
    "            return {key: ner_dict.get(key) for key in self.ner_keys}\n",
    "\n",
    "    \n",
    "    def quotes_count(self, row): #计算文本中引号的数量，用于检测文本中的引用。\n",
    "        summary = row['text']\n",
    "        text = row['prompt_text']\n",
    "        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n",
    "        if len(quotes_from_summary)>0:\n",
    "            return [quote in text for quote in quotes_from_summary].count(True)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def spelling(self, text): #计算文本中拼写错误的数量.\n",
    "        \n",
    "        wordlist=text.split()\n",
    "        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n",
    "\n",
    "        return amount_miss\n",
    "    \n",
    "    def add_spelling_dictionary(self, tokens: List[str]) -> List[str]: #将指定的单词列表添加到拼写检查的词典中。 \n",
    "        \"\"\"dictionary update for pyspell checker and autocorrect\"\"\"\n",
    "        self.spellchecker.word_frequency.load_words(tokens)\n",
    "        self.speller.nlp_data.update({token:1000 for token in tokens})\n",
    "    \n",
    "    def run(self, \n",
    "            prompts: pd.DataFrame,\n",
    "            summaries:pd.DataFrame,\n",
    "            mode:str\n",
    "        ) -> pd.DataFrame: #执行整个预处理流程。包括计算文本长度、拼写检查、特征生成等。\n",
    "        \n",
    "        # before merge preprocess\n",
    "        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(\n",
    "            lambda x: len(word_tokenize(x))\n",
    "        )\n",
    "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(\n",
    "            lambda x: word_tokenize(x)\n",
    "        )\n",
    "\n",
    "        summaries[\"summary_length\"] = summaries[\"text\"].apply(\n",
    "            lambda x: len(word_tokenize(x))\n",
    "        )\n",
    "        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(\n",
    "            lambda x: word_tokenize(x)\n",
    "        )\n",
    "        \n",
    "        # Add prompt tokens into spelling checker dictionary\n",
    "        prompts[\"prompt_tokens\"].apply(\n",
    "            lambda x: self.add_spelling_dictionary(x)\n",
    "        )\n",
    "        \n",
    "#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        # fix misspelling\n",
    "        summaries[\"fixed_summary_text\"] = summaries[\"text\"].progress_apply(\n",
    "            lambda x: self.speller(x)\n",
    "        )\n",
    "        \n",
    "        # count misspelling\n",
    "        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n",
    "        \n",
    "        # merge prompts and summaries\n",
    "        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n",
    "\n",
    "        # after merge preprocess\n",
    "        input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n",
    "        \n",
    "        input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n",
    "        input_df['bigram_overlap_count'] = input_df.progress_apply(\n",
    "            self.ngram_co_occurrence,args=(2,), axis=1 \n",
    "        )\n",
    "        input_df['bigram_overlap_ratio'] = input_df['bigram_overlap_count'] / (input_df['summary_length'] - 1)\n",
    "        \n",
    "        input_df['trigram_overlap_count'] = input_df.progress_apply(\n",
    "            self.ngram_co_occurrence, args=(3,), axis=1\n",
    "        )\n",
    "        input_df['trigram_overlap_ratio'] = input_df['trigram_overlap_count'] / (input_df['summary_length'] - 2)\n",
    "        \n",
    "        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n",
    "        \n",
    "        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n",
    "    \n",
    "preprocessor = Preprocessor(model_name=CFG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80539a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T02:38:02.400833Z",
     "iopub.status.busy": "2023-09-06T02:38:02.400273Z",
     "iopub.status.idle": "2023-09-06T02:38:03.235654Z",
     "shell.execute_reply": "2023-09-06T02:38:03.234750Z"
    },
    "papermill": {
     "duration": 0.846373,
     "end_time": "2023-09-06T02:38:03.238144",
     "exception": false,
     "start_time": "2023-09-06T02:38:02.391771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('/kaggle/input/train-data-fe/train_fe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38619170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T02:38:03.254674Z",
     "iopub.status.busy": "2023-09-06T02:38:03.254408Z",
     "iopub.status.idle": "2023-09-06T02:38:03.392608Z",
     "shell.execute_reply": "2023-09-06T02:38:03.391457Z"
    },
    "papermill": {
     "duration": 0.148685,
     "end_time": "2023-09-06T02:38:03.394694",
     "exception": false,
     "start_time": "2023-09-06T02:38:03.246009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 5221.67it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 9554.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 3523.88it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 3525.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 5895.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 4710.06it/s]\n"
     ]
    }
   ],
   "source": [
    "test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f2b98c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T02:38:03.413495Z",
     "iopub.status.busy": "2023-09-06T02:38:03.413266Z",
     "iopub.status.idle": "2023-09-06T02:38:03.421706Z",
     "shell.execute_reply": "2023-09-06T02:38:03.420891Z"
    },
    "papermill": {
     "duration": 0.020207,
     "end_time": "2023-09-06T02:38:03.423810",
     "exception": false,
     "start_time": "2023-09-06T02:38:03.403603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model Function Definition\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}\n",
    "\n",
    "def compute_mcrmse(eval_pred):\n",
    "    \"\"\"\n",
    "    Calculates mean columnwise root mean squared error\n",
    "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
    "    \"\"\"\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
    "    mcrmse = np.mean(col_rmse)\n",
    "\n",
    "    return {\n",
    "        \"content_rmse\": col_rmse[0],\n",
    "        \"wording_rmse\": col_rmse[1],\n",
    "        \"mcrmse\": mcrmse,\n",
    "    }\n",
    "\n",
    "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
    "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
    "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
    "    \n",
    "    return (content_score + wording_score)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70514a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T02:38:03.442055Z",
     "iopub.status.busy": "2023-09-06T02:38:03.441849Z",
     "iopub.status.idle": "2023-09-06T02:38:03.468498Z",
     "shell.execute_reply": "2023-09-06T02:38:03.467601Z"
    },
    "papermill": {
     "duration": 0.038622,
     "end_time": "2023-09-06T02:38:03.470832",
     "exception": false,
     "start_time": "2023-09-06T02:38:03.432210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentScoreRegressor:\n",
    "    def __init__(self, \n",
    "                model_name: str,\n",
    "                model_dir: str,\n",
    "                target: str,\n",
    "                hidden_dropout_prob: float,\n",
    "                attention_probs_dropout_prob: float,\n",
    "                max_length: int,\n",
    "                ):\n",
    "        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"fixed_summary_text\"]\n",
    "        self.input_col = \"input\"\n",
    "        \n",
    "        self.text_cols = [self.input_col] \n",
    "        self.target = target\n",
    "        self.target_cols = [target]\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.model_dir = model_dir\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        \n",
    "        self.model_config.update({\n",
    "            \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n",
    "            \"num_labels\": 1,\n",
    "            \"problem_type\": \"regression\",\n",
    "        })\n",
    "        \n",
    "        seed_everything(seed=42)\n",
    "\n",
    "        self.data_collator = DataCollatorWithPadding(\n",
    "            tokenizer=self.tokenizer\n",
    "        )\n",
    "\n",
    "\n",
    "    def tokenize_function(self, examples: pd.DataFrame):\n",
    "        labels = [examples[self.target]]\n",
    "        tokenized = self.tokenizer(examples[self.input_col],\n",
    "                         padding=False,\n",
    "                         truncation=True,\n",
    "                         max_length=self.max_length)\n",
    "        return {\n",
    "            **tokenized,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "    \n",
    "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
    "        tokenized = self.tokenizer(examples[self.input_col],\n",
    "                         padding=False,\n",
    "                         truncation=True,\n",
    "                         max_length=self.max_length)\n",
    "        return tokenized\n",
    "        \n",
    "    def train(self, \n",
    "            fold: int,\n",
    "            train_df: pd.DataFrame,\n",
    "            valid_df: pd.DataFrame,\n",
    "            batch_size: int,\n",
    "            learning_rate: float,\n",
    "            weight_decay: float,\n",
    "            num_train_epochs: float,\n",
    "            save_steps: int,\n",
    "        ) -> None:\n",
    "        \"\"\"fine-tuning\"\"\"\n",
    "        \n",
    "        sep = self.tokenizer.sep_token\n",
    "        train_df[self.input_col] = (\n",
    "                    train_df[\"prompt_title\"] + sep \n",
    "                    + train_df[\"prompt_question\"] + sep \n",
    "                    + train_df[\"fixed_summary_text\"]\n",
    "                  )\n",
    "        #However, while Deberta has an upper limit of 512 tokens, the number of tokens for a simple combination of \n",
    "        #\"prompt_text\", \"prompt_title\", and \"prompt_question\" may exceed 512.\n",
    "        #Because \"prompt_text\" has a large number of tokens, in this time, \n",
    "        #use for modeling with the fields \"prompt_title\", \"prompt_question\" and \"fixed_summary_text\".\n",
    "\n",
    "        valid_df[self.input_col] = (\n",
    "                    valid_df[\"prompt_title\"] + sep \n",
    "                    + valid_df[\"prompt_question\"] + sep \n",
    "                    + valid_df[\"fixed_summary_text\"]\n",
    "                  )\n",
    "        \n",
    "        train_df = train_df[[self.input_col] + self.target_cols]\n",
    "        valid_df = valid_df[[self.input_col] + self.target_cols]\n",
    "        \n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(\n",
    "            f\"/kaggle/input/{self.model_name}\", \n",
    "            config=self.model_config\n",
    "        )\n",
    "\n",
    "        train_dataset = Dataset.from_pandas(train_df, preserve_index=False) \n",
    "        val_dataset = Dataset.from_pandas(valid_df, preserve_index=False) \n",
    "    \n",
    "        train_tokenized_datasets = train_dataset.map(self.tokenize_function, batched=False)\n",
    "        val_tokenized_datasets = val_dataset.map(self.tokenize_function, batched=False)\n",
    "\n",
    "        # eg. \"bert/fold_0/\"\n",
    "        model_fold_dir = os.path.join(self.model_dir, str(fold)) \n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            load_best_model_at_end=True, # select best model\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            weight_decay=weight_decay,\n",
    "            report_to='none',\n",
    "            greater_is_better=False,\n",
    "            save_strategy=\"steps\",\n",
    "            evaluation_strategy=\"steps\",\n",
    "            eval_steps=save_steps,\n",
    "            save_steps=save_steps,\n",
    "            metric_for_best_model=\"rmse\",\n",
    "            save_total_limit=1\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model_content,\n",
    "            args=training_args,\n",
    "            train_dataset=train_tokenized_datasets,\n",
    "            eval_dataset=val_tokenized_datasets,\n",
    "            tokenizer=self.tokenizer,\n",
    "            compute_metrics=compute_metrics,\n",
    "            data_collator=self.data_collator\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        \n",
    "        model_content.save_pretrained(self.model_dir)\n",
    "        self.tokenizer.save_pretrained(self.model_dir)\n",
    "\n",
    "        \n",
    "    def predict(self, \n",
    "                test_df: pd.DataFrame,\n",
    "                fold: int,\n",
    "               ):\n",
    "        \"\"\"predict content score\"\"\"\n",
    "        \n",
    "        sep = self.tokenizer.sep_token\n",
    "        in_text = (\n",
    "                    test_df[\"prompt_title\"] + sep \n",
    "                    + test_df[\"prompt_question\"] + sep \n",
    "                    + test_df[\"fixed_summary_text\"]\n",
    "                  )\n",
    "        test_df[self.input_col] = in_text\n",
    "\n",
    "        test_ = test_df[[self.input_col]]\n",
    "    \n",
    "        test_dataset = Dataset.from_pandas(test_, preserve_index=False) \n",
    "        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n",
    "\n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(f\"{self.model_dir}\")\n",
    "        model_content.eval()\n",
    "        \n",
    "        # e.g. \"bert/fold_0/\"\n",
    "        model_fold_dir = os.path.join(self.model_dir, str(fold)) \n",
    "\n",
    "        test_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            do_train = False,\n",
    "            do_predict = True,\n",
    "            per_device_eval_batch_size = 4,   \n",
    "            dataloader_drop_last = False,\n",
    "        )\n",
    "\n",
    "        # init trainer\n",
    "        infer_content = Trainer(\n",
    "                      model = model_content, \n",
    "                      tokenizer=self.tokenizer,\n",
    "                      data_collator=self.data_collator,\n",
    "                      args = test_args)\n",
    "\n",
    "        preds = infer_content.predict(test_tokenized_dataset)[0]\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2d44a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T02:38:03.489584Z",
     "iopub.status.busy": "2023-09-06T02:38:03.489361Z",
     "iopub.status.idle": "2023-09-06T02:38:03.504815Z",
     "shell.execute_reply": "2023-09-06T02:38:03.503830Z"
    },
    "papermill": {
     "duration": 0.027735,
     "end_time": "2023-09-06T02:38:03.507272",
     "exception": false,
     "start_time": "2023-09-06T02:38:03.479537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_by_fold(\n",
    "        train_df: pd.DataFrame,\n",
    "        model_name: str,\n",
    "        target:str,\n",
    "        save_each_model: bool,\n",
    "        n_splits: int,\n",
    "        batch_size: int,\n",
    "        learning_rate: int,\n",
    "        hidden_dropout_prob: float,\n",
    "        attention_probs_dropout_prob: float,\n",
    "        weight_decay: float,\n",
    "        num_train_epochs: int,\n",
    "        save_steps: int,\n",
    "        max_length:int\n",
    "    ):\n",
    "\n",
    "    # delete old model files\n",
    "    if os.path.exists(model_name):\n",
    "        shutil.rmtree(model_name)\n",
    "    \n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        \n",
    "        train_data = train_df[train_df[\"fold\"] != fold]\n",
    "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
    "        \n",
    "        if save_each_model == True:\n",
    "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
    "        else: \n",
    "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
    "\n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir = model_dir, \n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        csr.train(\n",
    "            fold=fold,\n",
    "            train_df=train_data,\n",
    "            valid_df=valid_data, \n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            save_steps=save_steps,\n",
    "        )\n",
    "\n",
    "def validate(\n",
    "    train_df: pd.DataFrame,\n",
    "    target:str,\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length : int\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"predict oof data\"\"\"\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        \n",
    "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
    "        \n",
    "        if save_each_model == True:\n",
    "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
    "        else: \n",
    "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
    "        \n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir = model_dir,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        pred = csr.predict(\n",
    "            test_df=valid_data, \n",
    "            fold=fold\n",
    "        )\n",
    "        \n",
    "        train_df.loc[valid_data.index, f\"{target}_pred\"] = pred\n",
    "\n",
    "    return train_df\n",
    "    \n",
    "def predict(\n",
    "    test_df: pd.DataFrame,\n",
    "    target:str,\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length : int\n",
    "    ):\n",
    "    \"\"\"predict using mean folds\"\"\"\n",
    "\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        \n",
    "        if save_each_model == True:\n",
    "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
    "        else: \n",
    "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
    "\n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir = model_dir, \n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        pred = csr.predict(\n",
    "            test_df=test_df, \n",
    "            fold=fold\n",
    "        )\n",
    "        \n",
    "        test_df[f\"{target}_pred_{fold}\"] = pred\n",
    "    \n",
    "    test_df[f\"{target}\"] = test_df[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e887dca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T02:38:03.525890Z",
     "iopub.status.busy": "2023-09-06T02:38:03.525680Z",
     "iopub.status.idle": "2023-09-06T04:24:10.892588Z",
     "shell.execute_reply": "2023-09-06T04:24:10.891559Z"
    },
    "papermill": {
     "duration": 6367.37992,
     "end_time": "2023-09-06T04:24:10.895905",
     "exception": false,
     "start_time": "2023-09-06T02:38:03.515985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2130' max='2130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2130/2130 25:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285432</td>\n",
       "      <td>0.534259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.329048</td>\n",
       "      <td>0.573627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.259788</td>\n",
       "      <td>0.509694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239370</td>\n",
       "      <td>0.489255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.368199</td>\n",
       "      <td>0.606794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.371599</td>\n",
       "      <td>0.609590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.305132</td>\n",
       "      <td>0.552388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.200599</td>\n",
       "      <td>0.447883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.279097</td>\n",
       "      <td>0.528296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>0.359253</td>\n",
       "      <td>0.599378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>0.295146</td>\n",
       "      <td>0.543273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>0.301666</td>\n",
       "      <td>0.549242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>0.302401</td>\n",
       "      <td>0.549910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.148100</td>\n",
       "      <td>0.312234</td>\n",
       "      <td>0.558779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.328662</td>\n",
       "      <td>0.573290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.294199</td>\n",
       "      <td>0.542401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.294706</td>\n",
       "      <td>0.542869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.262168</td>\n",
       "      <td>0.512023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.285088</td>\n",
       "      <td>0.533936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.286528</td>\n",
       "      <td>0.535283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.303526</td>\n",
       "      <td>0.550932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 26:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.338348</td>\n",
       "      <td>0.581677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316171</td>\n",
       "      <td>0.562291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301113</td>\n",
       "      <td>0.548738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.434542</td>\n",
       "      <td>0.659198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.295099</td>\n",
       "      <td>0.543231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.260650</td>\n",
       "      <td>0.510539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.508528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.240851</td>\n",
       "      <td>0.490766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.277198</td>\n",
       "      <td>0.526496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.287190</td>\n",
       "      <td>0.535901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.264672</td>\n",
       "      <td>0.514463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.270261</td>\n",
       "      <td>0.519866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.292195</td>\n",
       "      <td>0.540551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.304075</td>\n",
       "      <td>0.551430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.301682</td>\n",
       "      <td>0.549255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.275397</td>\n",
       "      <td>0.524783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.291959</td>\n",
       "      <td>0.540332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.270580</td>\n",
       "      <td>0.520173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.269553</td>\n",
       "      <td>0.519185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.271509</td>\n",
       "      <td>0.521065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.284865</td>\n",
       "      <td>0.533728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2155' max='2155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2155/2155 25:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248529</td>\n",
       "      <td>0.498527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251588</td>\n",
       "      <td>0.501586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.211439</td>\n",
       "      <td>0.459825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.286649</td>\n",
       "      <td>0.535396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.238916</td>\n",
       "      <td>0.488790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.268399</td>\n",
       "      <td>0.518072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.352793</td>\n",
       "      <td>0.593963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.250521</td>\n",
       "      <td>0.500521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.236652</td>\n",
       "      <td>0.486468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.415187</td>\n",
       "      <td>0.644350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>0.525538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.255648</td>\n",
       "      <td>0.505617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.249197</td>\n",
       "      <td>0.499196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.326146</td>\n",
       "      <td>0.571092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.238066</td>\n",
       "      <td>0.487920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.256413</td>\n",
       "      <td>0.506372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.308969</td>\n",
       "      <td>0.555850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.338893</td>\n",
       "      <td>0.582145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.281036</td>\n",
       "      <td>0.530128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.264893</td>\n",
       "      <td>0.514678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.295577</td>\n",
       "      <td>0.543670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2530' max='2530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2530/2530 25:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.339507</td>\n",
       "      <td>0.582672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.493339</td>\n",
       "      <td>0.702381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.437933</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.536954</td>\n",
       "      <td>0.732771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.241500</td>\n",
       "      <td>0.405186</td>\n",
       "      <td>0.636542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.241500</td>\n",
       "      <td>0.509573</td>\n",
       "      <td>0.713844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.241500</td>\n",
       "      <td>0.455796</td>\n",
       "      <td>0.675127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.241500</td>\n",
       "      <td>0.373032</td>\n",
       "      <td>0.610763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.241500</td>\n",
       "      <td>0.282997</td>\n",
       "      <td>0.531975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.541058</td>\n",
       "      <td>0.735567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.412235</td>\n",
       "      <td>0.642055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.543441</td>\n",
       "      <td>0.737185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.541580</td>\n",
       "      <td>0.735921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.628519</td>\n",
       "      <td>0.792792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.568255</td>\n",
       "      <td>0.753827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.596821</td>\n",
       "      <td>0.772542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.489794</td>\n",
       "      <td>0.699852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.507046</td>\n",
       "      <td>0.712072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.455332</td>\n",
       "      <td>0.674783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.453860</td>\n",
       "      <td>0.673692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.568171</td>\n",
       "      <td>0.753771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.541585</td>\n",
       "      <td>0.735925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.560442</td>\n",
       "      <td>0.748627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.493404</td>\n",
       "      <td>0.702427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.515811</td>\n",
       "      <td>0.718200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv content rmse: 0.47706357175827424\n"
     ]
    }
   ],
   "source": [
    "for target in [\"content\"]:\n",
    "    train_by_fold(\n",
    "        train,\n",
    "        model_name=CFG.model_name,\n",
    "        save_each_model=True,\n",
    "        target=target,\n",
    "        learning_rate=CFG.learning_rate,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "        num_train_epochs=CFG.num_train_epochs,\n",
    "        n_splits=CFG.n_splits,\n",
    "        batch_size=CFG.batch_size,\n",
    "        save_steps=CFG.save_steps,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "    \n",
    "    \n",
    "    train = validate(\n",
    "        train,\n",
    "        target=target,\n",
    "        save_each_model=True,\n",
    "        model_name=CFG.model_name,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "\n",
    "    rmse = mean_squared_error(train[target], train[f\"{target}_pred\"], squared=False)\n",
    "    print(f\"cv {target} rmse: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3fa4941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T04:24:10.921977Z",
     "iopub.status.busy": "2023-09-06T04:24:10.921731Z",
     "iopub.status.idle": "2023-09-06T04:24:10.948327Z",
     "shell.execute_reply": "2023-09-06T04:24:10.947377Z"
    },
    "papermill": {
     "duration": 0.042892,
     "end_time": "2023-09-06T04:24:10.950991",
     "exception": false,
     "start_time": "2023-09-06T04:24:10.908099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>summary_length</th>\n",
       "      <th>fixed_summary_text</th>\n",
       "      <th>splling_err_num</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>...</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>word_overlap_count</th>\n",
       "      <th>bigram_overlap_count</th>\n",
       "      <th>bigram_overlap_ratio</th>\n",
       "      <th>trigram_overlap_count</th>\n",
       "      <th>trigram_overlap_ratio</th>\n",
       "      <th>quotes_count</th>\n",
       "      <th>fold</th>\n",
       "      <th>content_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>64</td>\n",
       "      <td>The third wave was an experimental see how peo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>...</td>\n",
       "      <td>660</td>\n",
       "      <td>0.096970</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.012526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>54</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>2</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>...</td>\n",
       "      <td>1076</td>\n",
       "      <td>0.050186</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>10</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.648804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>269</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>32</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>...</td>\n",
       "      <td>625</td>\n",
       "      <td>0.430400</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>0.194030</td>\n",
       "      <td>23</td>\n",
       "      <td>0.086142</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.306563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>28</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>5</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>...</td>\n",
       "      <td>625</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>5</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.012691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "      <td>232</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>29</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>...</td>\n",
       "      <td>660</td>\n",
       "      <td>0.351515</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>5</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.830672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
       "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
       "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
       "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
       "\n",
       "    content   wording  summary_length  \\\n",
       "0  0.205683  0.380538              64   \n",
       "1 -0.548304  0.506755              54   \n",
       "2  3.128928  4.231226             269   \n",
       "3 -0.210614 -0.471415              28   \n",
       "4  3.272894  3.219757             232   \n",
       "\n",
       "                                  fixed_summary_text  splling_err_num  \\\n",
       "0  The third wave was an experimental see how peo...                5   \n",
       "1  They would rub it up with soda to make the sme...                2   \n",
       "2  In Egypt, there were many occupations and soci...               32   \n",
       "3  The highest class was Pharaohs these people we...                5   \n",
       "4  The Third Wave developed  rapidly because the ...               29   \n",
       "\n",
       "                                     prompt_question  \\\n",
       "0  Summarize how the Third Wave developed over su...   \n",
       "1  Summarize the various ways the factory would u...   \n",
       "2  In complete sentences, summarize the structure...   \n",
       "3  In complete sentences, summarize the structure...   \n",
       "4  Summarize how the Third Wave developed over su...   \n",
       "\n",
       "                prompt_title  ... prompt_length  length_ratio  \\\n",
       "0             The Third Wave  ...           660      0.096970   \n",
       "1    Excerpt from The Jungle  ...          1076      0.050186   \n",
       "2  Egyptian Social Structure  ...           625      0.430400   \n",
       "3  Egyptian Social Structure  ...           625      0.044800   \n",
       "4             The Third Wave  ...           660      0.351515   \n",
       "\n",
       "   word_overlap_count  bigram_overlap_count  bigram_overlap_ratio  \\\n",
       "0                  14                     4              0.063492   \n",
       "1                  18                    22              0.415094   \n",
       "2                  22                    52              0.194030   \n",
       "3                   6                     6              0.222222   \n",
       "4                  23                    27              0.116883   \n",
       "\n",
       "   trigram_overlap_count  trigram_overlap_ratio  quotes_count  fold  \\\n",
       "0                      0               0.000000             0   3.0   \n",
       "1                     10               0.192308             0   2.0   \n",
       "2                     23               0.086142             2   1.0   \n",
       "3                      5               0.192308             0   1.0   \n",
       "4                      5               0.021739             4   3.0   \n",
       "\n",
       "   content_pred  \n",
       "0      0.012526  \n",
       "1     -0.648804  \n",
       "2      2.306563  \n",
       "3     -1.012691  \n",
       "4      1.830672  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2c90b16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T04:24:10.976779Z",
     "iopub.status.busy": "2023-09-06T04:24:10.976101Z",
     "iopub.status.idle": "2023-09-06T04:24:12.610494Z",
     "shell.execute_reply": "2023-09-06T04:24:12.609615Z"
    },
    "papermill": {
     "duration": 1.650049,
     "end_time": "2023-09-06T04:24:12.613103",
     "exception": false,
     "start_time": "2023-09-06T04:24:10.963054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_csv('train_content.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0a419",
   "metadata": {
    "papermill": {
     "duration": 0.011417,
     "end_time": "2023-09-06T04:24:12.636781",
     "exception": false,
     "start_time": "2023-09-06T04:24:12.625364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc8cc4",
   "metadata": {
    "papermill": {
     "duration": 0.011332,
     "end_time": "2023-09-06T04:24:12.659947",
     "exception": false,
     "start_time": "2023-09-06T04:24:12.648615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6426.671422,
   "end_time": "2023-09-06T04:24:16.360904",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-06T02:37:09.689482",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
