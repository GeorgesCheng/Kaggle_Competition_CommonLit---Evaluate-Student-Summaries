{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n!pip install /kaggle/input/textstat-pypi/Pyphen-0.9.3-py2.py3-none-any.whl\n!pip install /kaggle/input/textstat-pypi/textstat-0.7.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2023-08-08T17:39:52.693073Z","iopub.execute_input":"2023-08-08T17:39:52.693764Z","iopub.status.idle":"2023-08-08T17:41:30.446763Z","shell.execute_reply.started":"2023-08-08T17:39:52.693729Z","shell.execute_reply":"2023-08-08T17:41:30.445537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for new feat from feedback\nimport os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nfrom transformers import DataCollatorWithPadding\n%env TOKENIZERS_PARALLELISM=True\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\n\n# old \nimport os\n\nimport textstat\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-08-08T17:57:55.719178Z","iopub.execute_input":"2023-08-08T17:57:55.719596Z","iopub.status.idle":"2023-08-08T17:58:11.026941Z","shell.execute_reply.started":"2023-08-08T17:57:55.719563Z","shell.execute_reply":"2023-08-08T17:58:11.025885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG1:\n    model = \"microsoft/deberta-v3-base\"\n    path = \"../input/0911-deberta-v3-base/\"\n    base = \"../input/fb3models/microsoft-deberta-v3-base/\"\n    config_path = base + \"config/config.json\"\n    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n    gradient_checkpointing=False\n    batch_size=24\n    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n    seed=42\n    n_fold=10\n    trn_fold=list(range(n_fold))\n    num_workers= 0\n    weight = 1.0\n\nclass CFG8:\n    model = \"microsoft/deberta-v3-large\"\n    path = \"../input/0925-deberta-v3-large-unscale/\"\n    base = \"../input/fb3models/microsoft-deberta-v3-large/\"\n    config_path = base + \"config/config.json\"\n    tokenizer = AutoTokenizer.from_pretrained(base + 'tokenizer/')\n    gradient_checkpointing=False\n    batch_size= 16\n    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n    seed=42\n    n_fold=10\n    trn_fold=list(range(n_fold))\n    num_workers= 0 \n    weight = 1.0 # was 1.2\n\nCFG_list = [CFG1, CFG8]","metadata":{"execution":{"iopub.status.busy":"2023-08-08T17:58:11.028765Z","iopub.execute_input":"2023-08-08T17:58:11.029505Z","iopub.status.idle":"2023-08-08T17:58:11.791201Z","shell.execute_reply.started":"2023-08-08T17:58:11.029468Z","shell.execute_reply":"2023-08-08T17:58:11.790181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_mcrmse(eval_pred):\n    \"\"\"\n    Calculates mean columnwise root mean squared error\n    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n    \"\"\"\n    preds, labels = eval_pred\n\n    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n    mcrmse = np.mean(col_rmse)\n\n    return {\n        \"content_rmse\": col_rmse[0],\n        \"wording_rmse\": col_rmse[1],\n        \"mcrmse\": mcrmse,\n    }","metadata":{"execution":{"iopub.status.busy":"2023-08-08T17:58:15.566589Z","iopub.execute_input":"2023-08-08T17:58:15.566977Z","iopub.status.idle":"2023-08-08T17:58:15.57348Z","shell.execute_reply.started":"2023-08-08T17:58:15.566947Z","shell.execute_reply":"2023-08-08T17:58:15.572399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FROM OLD \n# ====================================================\n# Utils\n# ====================================================\ndef MCRMSE(y_trues, y_preds):\n    scores = []\n    idxes = y_trues.shape[1]\n    for i in range(idxes):\n        y_true = y_trues[:,i]\n        y_pred = y_preds[:,i]\n        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n        scores.append(score)\n    mcrmse_score = np.mean(scores)\n    return mcrmse_score, scores\n\ndef get_score(y_trues, y_preds):\n    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n    return mcrmse_score, scores\n\ndef get_logger(filename='inference'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)\n\n# ====================================================\n# oof\n# ====================================================\nfor CFG in CFG_list:\n    oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\n    labels = oof_df[CFG.target_cols].values\n    preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n    score, scores = get_score(labels, preds)\n    LOGGER.info(f'Model: {CFG.model} Score: {score:<.4f}  Scores: {scores}')\n    \n# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True, \n        #max_length=CFG.max_len,\n        #pad_to_max_length=True,\n        #truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['full_text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs\n\n# new for CL\nclass CommonlitDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs\n    \n# ====================================================\n# Model\n# ====================================================\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n\nclass MaxPooling(nn.Module):\n    def __init__(self):\n        super(MaxPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        embeddings = last_hidden_state.clone()\n        embeddings[input_mask_expanded == 0] = -1e4\n        max_embeddings, _ = torch.max(embeddings, dim = 1)\n        return max_embeddings\n    \nclass MinPooling(nn.Module):\n    def __init__(self):\n        super(MinPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        embeddings = last_hidden_state.clone()\n        embeddings[input_mask_expanded == 0] = 1e-4\n        min_embeddings, _ = torch.min(embeddings, dim = 1)\n        return min_embeddings\n        \n\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n            self.config.hidden_dropout = 0.\n            self.config.hidden_dropout_prob = 0.\n            self.config.attention_dropout = 0.\n            self.config.attention_probs_dropout_prob = 0.\n            LOGGER.info(self.config)\n        else:\n            self.config = AutoConfig.from_pretrained(config_path, output_hidden_states=True)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        if self.cfg.gradient_checkpointing:\n            self.model.gradient_checkpointing_enable()\n        self.pool = MeanPooling()\n        self.fc = nn.Linear(self.config.hidden_size, 6)\n        self._init_weights(self.fc)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(feature)\n        return output\n    \n# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in test_loader:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2023-08-08T17:58:15.750833Z","iopub.execute_input":"2023-08-08T17:58:15.75179Z","iopub.status.idle":"2023-08-08T17:58:15.985306Z","shell.execute_reply.started":"2023-08-08T17:58:15.751743Z","shell.execute_reply":"2023-08-08T17:58:15.982025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompts_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\")\nprompts_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\")\n\nsummaries_train = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\")\nsummaries_test = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\")\n\nsample_submission = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv\")\n\ntrain = summaries_train.merge(prompts_train, how=\"left\", on=\"prompt_id\")\ntest = summaries_test.merge(prompts_test, how=\"left\", on=\"prompt_id\")\n\ndisplay(prompts_train, train, test)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T17:58:16.147636Z","iopub.execute_input":"2023-08-08T17:58:16.14815Z","iopub.status.idle":"2023-08-08T17:58:16.304428Z","shell.execute_reply.started":"2023-08-08T17:58:16.148119Z","shell.execute_reply":"2023-08-08T17:58:16.303156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create some features using text statistics and use classic ML algorithm","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\nimport torch.nn.functional as F\n\n#Mean Pooling - Take attention mask into account for correct averaging\ndef mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n\n\n# Load model from HuggingFace Hub\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/input/sentence-transformers/minilm-l6-v2/all-MiniLM-L6-v2')\nmodel = AutoModel.from_pretrained('/kaggle/input/sentence-transformers/minilm-l6-v2/all-MiniLM-L6-v2')\nMEMORY = {}\n\ndef get_emb(sentences):\n    if sentences in MEMORY:\n        return MEMORY[sentences]\n    # Tokenize sentences\n    encoded_input = tokenizer([sentences], padding=True, truncation=True, return_tensors='pt')\n\n    # Compute token embeddings\n    with torch.no_grad():\n        model_output = model(**encoded_input)\n\n    # Perform pooling\n    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n\n    # Normalize embeddings\n    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)[0].detach().cpu().numpy()\n    MEMORY[sentences] = sentence_embeddings\n    \n    return sentence_embeddings\n\nSTOPWORDS = pd.read_csv(\"/kaggle/input/nltk-english-stopwords/nltk_eng_stopwords.csv\")[\"list_of_stopwords\"].tolist()\ndef get_stopwords_rel(text):\n    text_words = word_tokenize(text)\n    num_stopwords = sum([word in STOPWORDS for word in text_words])\n    \n    return num_stopwords/len(text_words)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T17:58:17.524676Z","iopub.execute_input":"2023-08-08T17:58:17.525054Z","iopub.status.idle":"2023-08-08T17:58:19.91499Z","shell.execute_reply.started":"2023-08-08T17:58:17.525024Z","shell.execute_reply":"2023-08-08T17:58:19.913894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_feedback_feat(data):\n    to_df = np.zeros((data.shape[0], len(CFG1.target_cols)))\n    for _idx, CFG in enumerate(CFG_list):\n        dataset = CommonlitDataset(CFG, data)\n        loader = DataLoader(dataset,\n                            batch_size=CFG.batch_size,\n                            shuffle=False,\n                            collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n                            num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n        predictions = []\n        for fold in CFG.trn_fold:\n            print('='*10, f'started fold {fold}', '='*10)\n            model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n            state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                               map_location=torch.device('cpu'))\n            model.load_state_dict(state['model'])\n            prediction = inference_fn(loader, model, device)\n            predictions.append(prediction)\n            del prediction\n            torch.cuda.empty_cache()\n        to_df += np.mean(predictions, axis=0) / len(CFG_list)\n        del model, dataset, loader; gc.collect()\n        torch.cuda.empty_cache() \n        \n    data[CFG.target_cols] = to_df\n    del predictions\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-08-08T17:58:19.916834Z","iopub.execute_input":"2023-08-08T17:58:19.917177Z","iopub.status.idle":"2023-08-08T17:58:19.932101Z","shell.execute_reply.started":"2023-08-08T17:58:19.91715Z","shell.execute_reply":"2023-08-08T17:58:19.931049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\ntqdm.pandas()\n\ndef get_stat_features(df, text_col=\"text\"):\n    df[\"num_unique_words\"] = df[text_col].apply(lambda x: len(set(x.split())))\n    df[\"num_words\"] = df[text_col].apply(lambda x: len(x.split()))\n    df[\"num_sentences\"] = df[text_col].apply(lambda x: len(x.split('.')))\n    df[\"isupper\"] = df[text_col].apply(lambda x: x[0].isupper())\n    df[\"mean_num_words\"] = df[text_col].apply(lambda x: np.mean([len(e.split()) for e in x.split('.')]))\n    df[\"mean_num_unique_words\"] = df[text_col].apply(lambda x: np.mean([len(set(e.split())) for e in x.split('.')]))\n    df[\"num_slash\"] = df[text_col].apply(lambda x: x.count(\"\\n\"))\n    df[\"paragraph_count\"] = train[text_col].apply(lambda x: x.count(\"\\n\\n\"))\n    df[\"upper_count\"] = df[text_col].apply(lambda x: np.sum([w.isupper() for w in x.split()])/len(x.split()))\n    df[\"syntax_count\"] = df[text_col].apply(lambda x: x.count(\",\") + x.count(\"-\") + x.count(\";\") + x.count(\":\"))\n    \n    df['diff_emb'] = df.progress_apply(lambda x: 1 - np.sum(get_emb(x[\"text\"])*get_emb(x[\"prompt_text\"])), axis=1)\n    \n    df['automated_readability_index'] = df[text_col].progress_apply(lambda x: textstat.automated_readability_index(x))\n    df['coleman_liau_index'] = df[text_col].progress_apply(lambda x: textstat.coleman_liau_index(x))\n    df['smog_index'] = df[text_col].progress_apply(lambda x: textstat.smog_index(x))\n    \n    df['dale_chall_readability_score'] = df[text_col].progress_apply(lambda x: textstat.dale_chall_readability_score(x))\n    df['linsear_write_formula'] = df[text_col].progress_apply(lambda x: textstat.linsear_write_formula(x))\n    df['gunning_fog'] = df[text_col].progress_apply(lambda x: textstat.gunning_fog(x))\n    df['text_standard_float'] = df[text_col].progress_apply(lambda x: textstat.text_standard(x, float_output=True))\n    df['spache_readability'] = df[text_col].progress_apply(lambda x: textstat.spache_readability(x))\n    df['rix'] = df[text_col].progress_apply(lambda x: textstat.rix(x))\n    df['lix'] = df[text_col].progress_apply(lambda x: textstat.lix(x))\n    \n    # new features \n    df[\"stopwords_rel\"] = df[text_col].progress_apply(lambda x: get_stopwords_rel(x))\n    \n    return df\n    \ntrain = get_stat_features(train)\ntest = get_stat_features(test)\n\ntrain = get_feedback_feat(train)\ntest = get_feedback_feat(test)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T13:50:00.654659Z","iopub.execute_input":"2023-08-05T13:50:00.655315Z","iopub.status.idle":"2023-08-05T14:35:32.198923Z","shell.execute_reply.started":"2023-08-05T13:50:00.655281Z","shell.execute_reply":"2023-08-05T14:35:32.196787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see corr matrix:","metadata":{}},{"cell_type":"code","source":"NO_FEATURES = [\"student_id\", \"prompt_id\", \"prompt_question\", \"prompt_title\", \"prompt_text\"]\nTARGETS = [\"content\", \"wording\"]\nFEATURES = [col for col in train.columns if col not in NO_FEATURES + TARGETS]\n\ncorr = train[FEATURES + TARGETS].corr()\ncorr.style.background_gradient(cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:35:32.199782Z","iopub.status.idle":"2023-08-05T14:35:32.200137Z","shell.execute_reply.started":"2023-08-05T14:35:32.199958Z","shell.execute_reply":"2023-08-05T14:35:32.199974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Learning catboost and check metric:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\nfrom catboost import CatBoostRegressor\n\nmodels = []\ngfk = GroupKFold(n_splits=4)\ntrain_oof = np.zeros((len(train), 2))\ntest_pred = np.zeros((len(test), 2))\nX, y = train[FEATURES], train[TARGETS]\nfor train_index, val_index in gfk.split(train, groups=train[\"prompt_id\"]):\n    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n    X_val, y_val = X.iloc[val_index], y.iloc[val_index]\n    \n    model = CatBoostRegressor(random_state=42, max_depth=4, \n                              objective=\"MultiRMSE\", text_features=[\"text\"])\n    model.fit(X_train, y_train, eval_set=(X_val, y_val), metric_period=100)\n    models.append(model)\n    \n    train_oof[val_index] = model.predict(X_val)\n    test_pred +=  model.predict(test[FEATURES])/4","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:35:32.202365Z","iopub.status.idle":"2023-08-05T14:35:32.203163Z","shell.execute_reply.started":"2023-08-05T14:35:32.202897Z","shell.execute_reply":"2023-08-05T14:35:32.20292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking competition metric:","metadata":{}},{"cell_type":"code","source":"compute_mcrmse((train_oof, train[TARGETS]))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:35:32.204546Z","iopub.status.idle":"2023-08-05T14:35:32.205326Z","shell.execute_reply.started":"2023-08-05T14:35:32.205077Z","shell.execute_reply":"2023-08-05T14:35:32.205101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# baseline version 4 + CFG1 - {'content_rmse': 0.5228984773032009, 'wording_rmse': 0.762959620336589, 'mcrmse': 0.642929048819895} - LB 0.536\n# baseline version 5 + CFG8 - {'content_rmse': 0.5337838213526346, 'wording_rmse': 0.7754182781358363, 'mcrmse': 0.6546010497442354} - LB 0.542","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:35:32.206683Z","iopub.status.idle":"2023-08-05T14:35:32.207472Z","shell.execute_reply.started":"2023-08-05T14:35:32.207214Z","shell.execute_reply":"2023-08-05T14:35:32.207236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_importance(df, best_model, height, top_n=50):\n\n    top_n = min(top_n, df.shape[1])\n\n    # Извлекаем значения из модели\n    fi = pd.DataFrame(index=df.columns, columns=[])\n    for i, m in enumerate(best_model):\n        fi[f\"m_{i}\"] = m.feature_importances_\n\n    fi = fi.stack().reset_index().iloc[:, [0, 2]]\n    fi.columns = [\"feature\", \"importance\"]\n\n    # Определяем порядок признаков и отбираем только n признаков для отрисовки\n    cols_ord = (\n        fi.groupby(\"feature\")[\"importance\"]\n        .mean()\n        .sort_values(ascending=False)\n        .index.tolist()[:top_n]\n    )\n\n    fi = fi[fi[\"feature\"].isin(cols_ord)]  # Выравниваем порядок по убыванию важности\n    print( \"Всего признаков {} Усреднее по {}-ти моделям: \".format(len(cols_ord), len(best_model)))\n\n    # Отрисовываем боксплоты фичей\n    plt.figure(figsize=(10, len(cols_ord) * height))\n    b = sns.boxplot(data=fi, y=\"feature\", x=\"importance\", orient=\"h\", order=cols_ord)\n\n    print(\"На график нанесено топ-{} признаков\".format(top_n))\n    return (\n        fi.groupby(by=[\"feature\"], as_index=False)[\"importance\"]\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)\n    )\n\n\ndf_feats_imp = plot_importance(\n    train[FEATURES],\n    models,\n    0.7,\n    top_n=40,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:35:32.208856Z","iopub.status.idle":"2023-08-05T14:35:32.209646Z","shell.execute_reply.started":"2023-08-05T14:35:32.209402Z","shell.execute_reply":"2023-08-05T14:35:32.209425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not bad!We need submit it!","metadata":{}},{"cell_type":"code","source":"sample_submission[\"content\"] = test_pred[:, 0]\nsample_submission[\"wording\"] = test_pred[:, 1]\n\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T14:35:32.211024Z","iopub.status.idle":"2023-08-05T14:35:32.211795Z","shell.execute_reply.started":"2023-08-05T14:35:32.211554Z","shell.execute_reply":"2023-08-05T14:35:32.211577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The main idea of this notebook, inspire comunity to not only train transformers, but to find new interesting solutions!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}